{"version":3,"sources":["../../src/helper/ingestGithubRepo.ts"],"sourcesContent":["// import { GSContext, GSStatus, PlainObject } from \"@godspeedsystems/core\";\r\nimport fetch from \"node-fetch\";\r\nimport * as fs from 'fs/promises';\r\nimport { VectorStore } from './vectorStore';\r\nimport pdfParse from 'pdf-parse';\r\nimport { createWorker } from 'tesseract.js';\r\nimport * as path from 'path';\r\nimport mammoth from \"mammoth\";\r\nimport { parse as htmlParse } from \"node-html-parser\";\r\n// import { VectorStore } from './vector_store';\r\n// import pdfParse from 'pdf-parse';\r\n// import { createWorker } from 'tesseract.js';\r\n// import dotenv from 'dotenv';\r\n// import { fileURLToPath } from 'url';\r\n\r\n// dotenv.config();\r\n\r\n// const __filename = fileURLToPath(import.meta.url);\r\n// const __dirname = path.dirname(__filename);\r\ninterface GitTreeItem {\r\n  path: string;\r\n  type: string;\r\n}\r\n\r\ninterface GitTreeResponse {\r\n  tree: GitTreeItem[];\r\n}\r\ninterface GitHubTree {\r\n  tree: { path: string; type: string }[];\r\n}\r\ninterface CommitResponse {\r\n  sha: string;\r\n}\r\ninterface FileChange {\r\n  filename: string;\r\n  status: 'added' | 'modified' | 'removed';\r\n}\r\n\r\ninterface CompareResponse {\r\n  files: FileChange[];\r\n}\r\n// const COMMIT_FILE = '../../data/last_commit.json';\r\n// const REPO_URL_FILE = '../../data/repo_url.json';\r\nconst COMMIT_FILE = path.resolve(__dirname, '../../data/last_commit.json');\r\nconst REPO_URL_FILE = path.resolve(__dirname, '../../data/repo_url.json');\r\n\r\nasync function saveLastCommit(repo: string, commitSha: string) {\r\n    await fs.writeFile(COMMIT_FILE, JSON.stringify({ repo, commit: commitSha }), 'utf-8');\r\n}\r\nasync function loadLastCommit(): Promise<{ repo?: string; commit?: string }> {\r\n    try {\r\n        const data = await fs.readFile(COMMIT_FILE, 'utf-8');\r\n        return JSON.parse(data);\r\n    } catch {\r\n        return {};\r\n    }\r\n}\r\n\r\nasync function loadRepoUrl() {\r\n    try {\r\n        const data = await fs.readFile(REPO_URL_FILE, 'utf-8');\r\n        return JSON.parse(data);\r\n    }\r\n    catch {\r\n        return {};\r\n    }\r\n}\r\nasync function getLatestCommitSha(owner: string, repo: string, branch: string): Promise<string> {\r\n    const url = `https://api.github.com/repos/${owner}/${repo}/commits/${branch}`;\r\n    const res = await fetch(url);\r\n    if (!res.ok) throw new Error(`Failed to fetch latest commit SHA: ${res.statusText}`);\r\n    const json = await res.json() as CommitResponse;\r\n    return json.sha;\r\n}\r\nasync function getChangedFiles(owner: string, repo: string, baseSha: string, headSha: string) {\r\n    const url = `https://api.github.com/repos/${owner}/${repo}/compare/${baseSha}...${headSha}`;\r\n    const res = await fetch(url);\r\n    if (!res.ok) throw new Error(`Failed to fetch changed files: ${res.statusText}`);\r\n    const json = await res.json() as CompareResponse;\r\n    const changed: string[] = [];\r\n    const deleted: string[] = [];\r\n\r\n    for (const file of json.files || []) {\r\n        if (file.status === 'modified' || file.status === 'added') changed.push(file.filename);\r\n        else if (file.status === 'removed') deleted.push(file.filename);\r\n    }\r\n    return { changed, deleted };\r\n}\r\nasync function extractTextFromPdf(buffer: Buffer): Promise<string> {\r\n    try {\r\n        const data = await pdfParse(buffer);\r\n        if (data.text && data.text.trim().length > 30) {\r\n            return data.text;\r\n        } else {\r\n            const worker = await createWorker();\r\n            const w = await worker as any;\r\n            await w.load();\r\n            await w.loadLanguage('eng');\r\n            await w.initialize('eng');\r\n            const { data: { text } } = await w.recognize(buffer);\r\n            await w.terminate();\r\n            return text;\r\n        }\r\n    } catch (e) {\r\n        return '';\r\n    }\r\n}\r\nasync function ingestChangedFiles(repoUrl: string, branch = 'main'): Promise<void> {\r\n    // const { repoUrl, branch = 'main' } = args;\r\n    console.log(\"Entering...\")\r\n    const parts = repoUrl.replace(/\\/$/, '').split('/');\r\n    const owner = parts[parts.length - 2];\r\n    const repo = parts[parts.length - 1];\r\n    const latestSha = await getLatestCommitSha(owner, repo, branch);\r\n    console.log(\"Got latest sha..\")\r\n    const state = await loadLastCommit();\r\n    console.log(\"Got last commit...\")\r\n    if (state.repo === repo && state.commit === latestSha) {\r\n        console.log('No new commit. Skipping ingestion.');\r\n        return;\r\n    }\r\n    const vs = new VectorStore();\r\n    console.log(\"Created vectorstore..\")\r\n    let changedFiles: string[] = [];\r\n    let deletedFiles: string[] = [];\r\n    if (state.repo === repo && state.commit) {\r\n        console.log(\"Getting changed files\")\r\n        const changes = await getChangedFiles(owner, repo, state.commit, latestSha);\r\n        changedFiles = changes.changed;\r\n        deletedFiles = changes.deleted;\r\n    }\r\n    else {\r\n        // First time: get all files from HEAD\r\n        const treeUrl = `https://api.github.com/repos/${owner}/${repo}/git/trees/${branch}?recursive=1`;\r\n        const treeRes = await fetch(treeUrl);\r\n        console.log(\"Got tree....\")\r\n        if (!treeRes.ok)\r\n            throw new Error(`Failed to fetch repo tree: ${treeRes.statusText}`);\r\n        const treeJson = (await treeRes.json()) as GitHubTree;\r\n        changedFiles = treeJson.tree\r\n            .filter((f: any) => f.type === 'blob')\r\n            .map((f: any) => f.path);\r\n        console.log(\"Got changed files...\")\r\n        deletedFiles = [];\r\n    }\r\n    for (const filePath of deletedFiles) {\r\n        console.log(`Removing deleted file from vector DB: ${filePath}`);\r\n        await vs.removeDocument(filePath);\r\n    }\r\n    const allowedExts = new Set(['.md', '.txt', '.pdf', '.mdx']);\r\n    for (const filePath of changedFiles) {\r\n        try {\r\n            const ext = path.extname(filePath).toLowerCase();\r\n            if (!allowedExts.has(ext))\r\n                continue;\r\n            const rawUrl = `https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${filePath}`;\r\n            const contentRes = await fetch(rawUrl);\r\n            console.log(\"Got content...\")\r\n            if (!contentRes.ok) {\r\n                console.log(`Failed to fetch content for: ${filePath} (status ${contentRes.status})`);\r\n                continue;\r\n            }\r\n            let content;\r\n            if (ext === '.pdf') {\r\n                const buffer = await contentRes.buffer();\r\n                content = await extractTextFromPdf(buffer);\r\n            }\r\n            else {\r\n                content = await contentRes.text();\r\n            }\r\n            if (content.length > 0) {\r\n                console.log(`Re-ingesting file: ${filePath}`);\r\n                await vs.removeDocument(filePath);\r\n                console.log(\"Done removal...\")\r\n                await vs.upsert(filePath, content);\r\n            }\r\n        }\r\n        catch (e) {\r\n            console.error(`Error processing file ${filePath}:`, e);\r\n        }\r\n    }\r\n    await saveLastCommit(repo, latestSha);\r\n    console.log('Ingestion complete.');\r\n}\r\n\r\nasync function ingestUploadedFile(file: string, filename: string): Promise<string> {\r\n  \r\n    const ext = path.extname(filename).toLowerCase();\r\n    const buffer = Buffer.from(file, \"base64\");\r\n\r\n    let content = \"\";\r\n\r\n  \r\n    switch (ext) {\r\n        case \".pdf\":\r\n          const pdf = await extractTextFromPdf(buffer);\r\n          content = pdf;\r\n          break;\r\n  \r\n        case \".docx\":\r\n          const result = await mammoth.extractRawText({ buffer });\r\n          content = result.value;\r\n          break;\r\n  \r\n        case \".txt\":\r\n        case \".md\":\r\n          content = buffer.toString(\"utf-8\");\r\n          break;\r\n  \r\n        case \".html\":\r\n          const root = htmlParse(buffer.toString(\"utf-8\"));\r\n          content = root.text;\r\n          break;\r\n  \r\n        default:\r\n          return `Unsupported file type: ${ext}`\r\n      }\r\n\r\n    const vs = new VectorStore();\r\n    const docId = path.basename(filename, path.extname(filename));\r\n    console.log(`[${docId}] Starting ingestion.`);\r\n\r\n    // Step 1: Split by pages or sections\r\n    const pages = content.split(/\\n{2,}/).filter(p => p.trim().length > 0);\r\n    console.log(`[${docId}] ${pages.length} logical pages found.`);\r\n\r\n    // Step 2: Process each page\r\n    for (let i = 0; i < pages.length; i++) {\r\n      const pageContent = pages[i];\r\n      const pageId = `${docId}_page_${i + 1}`;\r\n\r\n      vs.upsert(pageId,pageContent)\r\n\r\n    }\r\n    return `Document '${filename}' ingested successfully.`\r\n         \r\n}\r\n\r\nexport { ingestChangedFiles, loadRepoUrl, ingestUploadedFile}\r\n\r\n//     const repoUrl=ctx.config.repoUrl;\r\n//     const branch= 'main';\r\n\r\n//     if (!repoUrl) {\r\n//         return new GSStatus(false, 400, 'Missing repoUrl in args');\r\n//     }\r\n\r\n//     try {\r\n//         ctx.logger.info(`Starting ingestion from ${repoUrl}`);\r\n//         const parts = repoUrl.replace(/\\/$/, '').split('/');\r\n//         const owner = parts[parts.length - 2];\r\n//         const repo = parts[parts.length - 1];\r\n\r\n//         const latestSha = await getLatestCommitSha(owner, repo, branch);\r\n//         const state = await loadLastCommit();\r\n\r\n//         if (state.repo === repo && state.commit === latestSha) {\r\n//             ctx.logger.info('No new commit. Skipping ingestion.');\r\n//             return new GSStatus(true, 200, undefined, { message: 'No update needed.' });\r\n//         }\r\n\r\n//         const vs = ctx.functions.vector_store;\r\n//         let changedFiles: string[] = [];\r\n//         let deletedFiles: string[] = [];\r\n\r\n//         if (state.repo === repo && state.commit) {\r\n//             const changes = await getChangedFiles(owner, repo, state.commit, latestSha);\r\n//             changedFiles = changes.changed;\r\n//             deletedFiles = changes.deleted;\r\n//         } else {\r\n//             const treeUrl = `https://api.github.com/repos/${owner}/${repo}/git/trees/${branch}?recursive=1`;\r\n//             const treeRes = await fetch(treeUrl);\r\n//             if (!treeRes.ok) throw new Error(`Failed to fetch repo tree: ${treeRes.statusText}`);\r\n//             const treeJson = await treeRes.json() as GitTreeResponse;\r\n//             changedFiles = treeJson.tree.filter((f: any) => f.type === 'blob').map((f: any) => f.path);\r\n//         }\r\n\r\n//         for (const filePath of deletedFiles) {\r\n//             ctx.childLogger.info(`Removing deleted file: ${filePath}`);\r\n//             await vs.removeDocument(filePath);\r\n//         }\r\n\r\n//         const allowedExts = new Set(['.md', '.txt', '.pdf', '.mdx']);\r\n//         for (const filePath of changedFiles) {\r\n//             try {\r\n//                 const ext = path.extname(filePath).toLowerCase();\r\n//                 if (!allowedExts.has(ext)) continue;\r\n\r\n//                 const rawUrl = `https://raw.githubusercontent.com/${owner}/${repo}/${branch}/${filePath}`;\r\n//                 const contentRes = await fetch(rawUrl);\r\n//                 if (!contentRes.ok) continue;\r\n\r\n//                 let content: string;\r\n//                 // if (ext === '.pdf') {\r\n//                 //     const buffer = await contentRes.buffer();\r\n//                 //     content = await extractTextFromPdf(buffer);\r\n//                 // } else {\r\n//                     content = await contentRes.text();\r\n//                 // }\r\n//                 // ctx.logger.info(content)\r\n\r\n//                 if (content.length > 0) {\r\n//                     ctx.logger.info('reached ')\r\n//                     // await vs.removeDocument(filePath);\r\n//                     // await vs.upsert(filePath, content);\r\n//                     await vs(ctx, { docId: filePath, mode: 'remove' });\r\n//                     await vs(ctx, { docId: filePath, content, mode: 'upsert' });\r\n\r\n//                     ctx.childLogger.info(`Upserted ${filePath}`);\r\n//                 }\r\n//             } catch (err) {\r\n//                 ctx.childLogger.error(`Error processing ${filePath}: %o`, err);\r\n//             }\r\n//         }\r\n\r\n//         await saveLastCommit(repo, latestSha);\r\n//         return new GSStatus(true, 200, undefined, { message: 'Ingestion complete.', changedFiles });\r\n//     } catch (err: any) {\r\n//         ctx.logger.error(`Ingestion failed: %o`, err);\r\n//         return new GSStatus(false, 500, 'GitHub ingestion error', { error: err.message });\r\n//     }\r\n// }\r\n"],"names":["ingestChangedFiles","ingestUploadedFile","loadRepoUrl","COMMIT_FILE","path","resolve","__dirname","REPO_URL_FILE","saveLastCommit","repo","commitSha","fs","writeFile","JSON","stringify","commit","loadLastCommit","data","readFile","parse","getLatestCommitSha","owner","branch","url","res","fetch","ok","Error","statusText","json","sha","getChangedFiles","baseSha","headSha","changed","deleted","file","files","status","push","filename","extractTextFromPdf","buffer","pdfParse","text","trim","length","worker","createWorker","w","load","loadLanguage","initialize","recognize","terminate","e","repoUrl","console","log","parts","replace","split","latestSha","state","vs","VectorStore","changedFiles","deletedFiles","changes","treeUrl","treeRes","treeJson","tree","filter","f","type","map","filePath","removeDocument","allowedExts","Set","ext","extname","toLowerCase","has","rawUrl","contentRes","content","upsert","error","Buffer","from","pdf","result","mammoth","extractRawText","value","toString","root","htmlParse","docId","basename","pages","p","i","pageContent","pageId"],"mappings":"AAAA,4EAA4E;;;;;;;;;;;;QA8OnEA;eAAAA;;QAAiCC;eAAAA;;QAAbC;eAAAA;;;kEA7OX;kEACE;6BACQ;iEACP;2BACQ;8DACP;gEACF;gCACe;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiCnC,qDAAqD;AACrD,oDAAoD;AACpD,MAAMC,cAAcC,MAAKC,OAAO,CAACC,WAAW;AAC5C,MAAMC,gBAAgBH,MAAKC,OAAO,CAACC,WAAW;AAE9C,SAAeE,eAAeC,IAAY,EAAEC,SAAiB;;QACzD,MAAMC,UAAGC,SAAS,CAACT,aAAaU,KAAKC,SAAS,CAAC;YAAEL;YAAMM,QAAQL;QAAU,IAAI;IACjF;;AACA,SAAeM;;QACX,IAAI;YACA,MAAMC,OAAO,MAAMN,UAAGO,QAAQ,CAACf,aAAa;YAC5C,OAAOU,KAAKM,KAAK,CAACF;QACtB,EAAE,UAAM;YACJ,OAAO,CAAC;QACZ;IACJ;;AAEA,SAAef;;QACX,IAAI;YACA,MAAMe,OAAO,MAAMN,UAAGO,QAAQ,CAACX,eAAe;YAC9C,OAAOM,KAAKM,KAAK,CAACF;QACtB,EACA,UAAM;YACF,OAAO,CAAC;QACZ;IACJ;;AACA,SAAeG,mBAAmBC,KAAa,EAAEZ,IAAY,EAAEa,MAAc;;QACzE,MAAMC,MAAM,CAAC,6BAA6B,EAAEF,MAAM,CAAC,EAAEZ,KAAK,SAAS,EAAEa,QAAQ;QAC7E,MAAME,MAAM,MAAMC,IAAAA,kBAAK,EAACF;QACxB,IAAI,CAACC,IAAIE,EAAE,EAAE,MAAM,IAAIC,MAAM,CAAC,mCAAmC,EAAEH,IAAII,UAAU,EAAE;QACnF,MAAMC,OAAO,MAAML,IAAIK,IAAI;QAC3B,OAAOA,KAAKC,GAAG;IACnB;;AACA,SAAeC,gBAAgBV,KAAa,EAAEZ,IAAY,EAAEuB,OAAe,EAAEC,OAAe;;QACxF,MAAMV,MAAM,CAAC,6BAA6B,EAAEF,MAAM,CAAC,EAAEZ,KAAK,SAAS,EAAEuB,QAAQ,GAAG,EAAEC,SAAS;QAC3F,MAAMT,MAAM,MAAMC,IAAAA,kBAAK,EAACF;QACxB,IAAI,CAACC,IAAIE,EAAE,EAAE,MAAM,IAAIC,MAAM,CAAC,+BAA+B,EAAEH,IAAII,UAAU,EAAE;QAC/E,MAAMC,OAAO,MAAML,IAAIK,IAAI;QAC3B,MAAMK,UAAoB,EAAE;QAC5B,MAAMC,UAAoB,EAAE;QAE5B,KAAK,MAAMC,QAAQP,KAAKQ,KAAK,IAAI,EAAE,CAAE;YACjC,IAAID,KAAKE,MAAM,KAAK,cAAcF,KAAKE,MAAM,KAAK,SAASJ,QAAQK,IAAI,CAACH,KAAKI,QAAQ;iBAChF,IAAIJ,KAAKE,MAAM,KAAK,WAAWH,QAAQI,IAAI,CAACH,KAAKI,QAAQ;QAClE;QACA,OAAO;YAAEN;YAASC;QAAQ;IAC9B;;AACA,SAAeM,mBAAmBC,MAAc;;QAC5C,IAAI;YACA,MAAMzB,OAAO,MAAM0B,IAAAA,iBAAQ,EAACD;YAC5B,IAAIzB,KAAK2B,IAAI,IAAI3B,KAAK2B,IAAI,CAACC,IAAI,GAAGC,MAAM,GAAG,IAAI;gBAC3C,OAAO7B,KAAK2B,IAAI;YACpB,OAAO;gBACH,MAAMG,SAAS,MAAMC,IAAAA,uBAAY;gBACjC,MAAMC,IAAI,MAAMF;gBAChB,MAAME,EAAEC,IAAI;gBACZ,MAAMD,EAAEE,YAAY,CAAC;gBACrB,MAAMF,EAAEG,UAAU,CAAC;gBACnB,MAAM,EAAEnC,MAAM,EAAE2B,IAAI,EAAE,EAAE,GAAG,MAAMK,EAAEI,SAAS,CAACX;gBAC7C,MAAMO,EAAEK,SAAS;gBACjB,OAAOV;YACX;QACJ,EAAE,OAAOW,GAAG;YACR,OAAO;QACX;IACJ;;AACA,SAAevD,mBAAmBwD,OAAe,EAAElC,SAAS,MAAM;;QAC9D,6CAA6C;QAC7CmC,QAAQC,GAAG,CAAC;QACZ,MAAMC,QAAQH,QAAQI,OAAO,CAAC,OAAO,IAAIC,KAAK,CAAC;QAC/C,MAAMxC,QAAQsC,KAAK,CAACA,MAAMb,MAAM,GAAG,EAAE;QACrC,MAAMrC,OAAOkD,KAAK,CAACA,MAAMb,MAAM,GAAG,EAAE;QACpC,MAAMgB,YAAY,MAAM1C,mBAAmBC,OAAOZ,MAAMa;QACxDmC,QAAQC,GAAG,CAAC;QACZ,MAAMK,QAAQ,MAAM/C;QACpByC,QAAQC,GAAG,CAAC;QACZ,IAAIK,MAAMtD,IAAI,KAAKA,QAAQsD,MAAMhD,MAAM,KAAK+C,WAAW;YACnDL,QAAQC,GAAG,CAAC;YACZ;QACJ;QACA,MAAMM,KAAK,IAAIC,wBAAW;QAC1BR,QAAQC,GAAG,CAAC;QACZ,IAAIQ,eAAyB,EAAE;QAC/B,IAAIC,eAAyB,EAAE;QAC/B,IAAIJ,MAAMtD,IAAI,KAAKA,QAAQsD,MAAMhD,MAAM,EAAE;YACrC0C,QAAQC,GAAG,CAAC;YACZ,MAAMU,UAAU,MAAMrC,gBAAgBV,OAAOZ,MAAMsD,MAAMhD,MAAM,EAAE+C;YACjEI,eAAeE,QAAQlC,OAAO;YAC9BiC,eAAeC,QAAQjC,OAAO;QAClC,OACK;YACD,sCAAsC;YACtC,MAAMkC,UAAU,CAAC,6BAA6B,EAAEhD,MAAM,CAAC,EAAEZ,KAAK,WAAW,EAAEa,OAAO,YAAY,CAAC;YAC/F,MAAMgD,UAAU,MAAM7C,IAAAA,kBAAK,EAAC4C;YAC5BZ,QAAQC,GAAG,CAAC;YACZ,IAAI,CAACY,QAAQ5C,EAAE,EACX,MAAM,IAAIC,MAAM,CAAC,2BAA2B,EAAE2C,QAAQ1C,UAAU,EAAE;YACtE,MAAM2C,WAAY,MAAMD,QAAQzC,IAAI;YACpCqC,eAAeK,SAASC,IAAI,CACvBC,MAAM,CAAC,CAACC,IAAWA,EAAEC,IAAI,KAAK,QAC9BC,GAAG,CAAC,CAACF,IAAWA,EAAEtE,IAAI;YAC3BqD,QAAQC,GAAG,CAAC;YACZS,eAAe,EAAE;QACrB;QACA,KAAK,MAAMU,YAAYV,aAAc;YACjCV,QAAQC,GAAG,CAAC,CAAC,sCAAsC,EAAEmB,UAAU;YAC/D,MAAMb,GAAGc,cAAc,CAACD;QAC5B;QACA,MAAME,cAAc,IAAIC,IAAI;YAAC;YAAO;YAAQ;YAAQ;SAAO;QAC3D,KAAK,MAAMH,YAAYX,aAAc;YACjC,IAAI;gBACA,MAAMe,MAAM7E,MAAK8E,OAAO,CAACL,UAAUM,WAAW;gBAC9C,IAAI,CAACJ,YAAYK,GAAG,CAACH,MACjB;gBACJ,MAAMI,SAAS,CAAC,kCAAkC,EAAEhE,MAAM,CAAC,EAAEZ,KAAK,CAAC,EAAEa,OAAO,CAAC,EAAEuD,UAAU;gBACzF,MAAMS,aAAa,MAAM7D,IAAAA,kBAAK,EAAC4D;gBAC/B5B,QAAQC,GAAG,CAAC;gBACZ,IAAI,CAAC4B,WAAW5D,EAAE,EAAE;oBAChB+B,QAAQC,GAAG,CAAC,CAAC,6BAA6B,EAAEmB,SAAS,SAAS,EAAES,WAAWhD,MAAM,CAAC,CAAC,CAAC;oBACpF;gBACJ;gBACA,IAAIiD;gBACJ,IAAIN,QAAQ,QAAQ;oBAChB,MAAMvC,SAAS,MAAM4C,WAAW5C,MAAM;oBACtC6C,UAAU,MAAM9C,mBAAmBC;gBACvC,OACK;oBACD6C,UAAU,MAAMD,WAAW1C,IAAI;gBACnC;gBACA,IAAI2C,QAAQzC,MAAM,GAAG,GAAG;oBACpBW,QAAQC,GAAG,CAAC,CAAC,mBAAmB,EAAEmB,UAAU;oBAC5C,MAAMb,GAAGc,cAAc,CAACD;oBACxBpB,QAAQC,GAAG,CAAC;oBACZ,MAAMM,GAAGwB,MAAM,CAACX,UAAUU;gBAC9B;YACJ,EACA,OAAOhC,GAAG;gBACNE,QAAQgC,KAAK,CAAC,CAAC,sBAAsB,EAAEZ,SAAS,CAAC,CAAC,EAAEtB;YACxD;QACJ;QACA,MAAM/C,eAAeC,MAAMqD;QAC3BL,QAAQC,GAAG,CAAC;IAChB;;AAEA,SAAezD,mBAAmBmC,IAAY,EAAEI,QAAgB;;QAE5D,MAAMyC,MAAM7E,MAAK8E,OAAO,CAAC1C,UAAU2C,WAAW;QAC9C,MAAMzC,SAASgD,OAAOC,IAAI,CAACvD,MAAM;QAEjC,IAAImD,UAAU;QAGd,OAAQN;YACJ,KAAK;gBACH,MAAMW,MAAM,MAAMnD,mBAAmBC;gBACrC6C,UAAUK;gBACV;YAEF,KAAK;gBACH,MAAMC,SAAS,MAAMC,gBAAO,CAACC,cAAc,CAAC;oBAAErD;gBAAO;gBACrD6C,UAAUM,OAAOG,KAAK;gBACtB;YAEF,KAAK;YACL,KAAK;gBACHT,UAAU7C,OAAOuD,QAAQ,CAAC;gBAC1B;YAEF,KAAK;gBACH,MAAMC,OAAOC,IAAAA,qBAAS,EAACzD,OAAOuD,QAAQ,CAAC;gBACvCV,UAAUW,KAAKtD,IAAI;gBACnB;YAEF;gBACE,OAAO,CAAC,uBAAuB,EAAEqC,KAAK;QAC1C;QAEF,MAAMjB,KAAK,IAAIC,wBAAW;QAC1B,MAAMmC,QAAQhG,MAAKiG,QAAQ,CAAC7D,UAAUpC,MAAK8E,OAAO,CAAC1C;QACnDiB,QAAQC,GAAG,CAAC,CAAC,CAAC,EAAE0C,MAAM,qBAAqB,CAAC;QAE5C,qCAAqC;QACrC,MAAME,QAAQf,QAAQ1B,KAAK,CAAC,UAAUY,MAAM,CAAC8B,CAAAA,IAAKA,EAAE1D,IAAI,GAAGC,MAAM,GAAG;QACpEW,QAAQC,GAAG,CAAC,CAAC,CAAC,EAAE0C,MAAM,EAAE,EAAEE,MAAMxD,MAAM,CAAC,qBAAqB,CAAC;QAE7D,4BAA4B;QAC5B,IAAK,IAAI0D,IAAI,GAAGA,IAAIF,MAAMxD,MAAM,EAAE0D,IAAK;YACrC,MAAMC,cAAcH,KAAK,CAACE,EAAE;YAC5B,MAAME,SAAS,GAAGN,MAAM,MAAM,EAAEI,IAAI,GAAG;YAEvCxC,GAAGwB,MAAM,CAACkB,QAAOD;QAEnB;QACA,OAAO,CAAC,UAAU,EAAEjE,SAAS,wBAAwB,CAAC;IAE1D;;CAIA,wCAAwC;CACxC,4BAA4B;CAE5B,sBAAsB;CACtB,sEAAsE;CACtE,QAAQ;CAER,YAAY;CACZ,iEAAiE;CACjE,+DAA+D;CAC/D,iDAAiD;CACjD,gDAAgD;CAEhD,2EAA2E;CAC3E,gDAAgD;CAEhD,mEAAmE;CACnE,qEAAqE;CACrE,2FAA2F;CAC3F,YAAY;CAEZ,iDAAiD;CACjD,2CAA2C;CAC3C,2CAA2C;CAE3C,qDAAqD;CACrD,2FAA2F;CAC3F,8CAA8C;CAC9C,8CAA8C;CAC9C,mBAAmB;CACnB,+GAA+G;CAC/G,oDAAoD;CACpD,oGAAoG;CACpG,wEAAwE;CACxE,0GAA0G;CAC1G,YAAY;CAEZ,iDAAiD;CACjD,0EAA0E;CAC1E,iDAAiD;CACjD,YAAY;CAEZ,wEAAwE;CACxE,iDAAiD;CACjD,oBAAoB;CACpB,oEAAoE;CACpE,uDAAuD;CAEvD,6GAA6G;CAC7G,0DAA0D;CAC1D,gDAAgD;CAEhD,uCAAuC;CACvC,2CAA2C;CAC3C,mEAAmE;CACnE,qEAAqE;CACrE,8BAA8B;CAC9B,yDAAyD;CACzD,uBAAuB;CACvB,8CAA8C;CAE9C,4CAA4C;CAC5C,kDAAkD;CAClD,4DAA4D;CAC5D,6DAA6D;CAC7D,0EAA0E;CAC1E,mFAAmF;CAEnF,oEAAoE;CACpE,oBAAoB;CACpB,8BAA8B;CAC9B,kFAAkF;CAClF,gBAAgB;CAChB,YAAY;CAEZ,iDAAiD;CACjD,uGAAuG;CACvG,2BAA2B;CAC3B,yDAAyD;CACzD,6FAA6F;CAC7F,QAAQ;CACR,IAAI"}